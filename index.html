<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Sina Alemohammad</title>

    <meta name="author" content="Sina Alemohammad">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Sina Alemohammad
                </p>
                <p>

		I am a postdoctoral fellow in <a href="https://www.vita-group.space/">VITA</a> group in University of Texas at Austin, working with <a href="https://www.ece.utexas.edu/people/faculty/atlas-wang">Prof. Atlas Wang</a>.
		I obtained my Ph.D. in Electiocal and Computer Engineering at Rice Univeristy, under supercision of <a href="https://richb.rice.edu/">Prof. Richard Baraniuk</a>. I was a recipient of the Ken Kennedy Fellowship at Rice.	
		My research focuses on deep learning theory and generative models.
                </p>
                <p style="text-align:center">
                  <a href="mailto:sinaalemohammad@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/SinaAlemohammadCV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.co.il/citations?user=ATjmZVsAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/SinaAlmd">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/SinaAlemohammad">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/sinapic.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/sinapic.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  Recent advances in generative modeling have led to a widespread rise in synthetic data across online content. As a result, it has become increasingly common, intentionally or unintentionally, for newer models to be trained on data generated by earlier ones. In my research, I introduced the concept of Model Autophagy Disorder (MAD), a phenomenon that occurs when models repeatedly rely on their own synthetic outputs. This feedback loop gradually degrades the realism and diversity of the generated data, causing a drift away from the true data distribution, even when real data remains available.<p>
		</p>
		      
		<p>
		My current research is centered on understanding and preventing MAD in generative models. I am particularly interested in developing strategies that enable models to self-improve using synthetic data without falling into the pitfalls of self-consuming feedback. This involves designing systems that can harness the benefits of synthetic training signals while preserving alignment with real-world data distributions. More broadly, my interests include deep learning theory, generative modeling, and sparse signal processing.
		</p>
		<p>
		My works has been featured in multiple news sources, e.g.,  <a href="https://www.nytimes.com/interactive/2024/08/26/upshot/ai-synthetic-data.html">The New York Times</a>, <a href="https://www.newscientist.com/article/2382519-ais-trained-on-ai-generated-images-produce-glitches-and-blurs/">New Scientist</a>, <a href="https://futurism.com/ai-trained-ai-generated-data">Futurism</a>,
		<a href="https://www.telegraph.co.uk/business/2024/02/01/why-ai-new-age-of-fake-news-and-disinformation/">The Telegraph</a>,
		<a href="https://finance.yahoo.com/news/ais-mad-cow-disease-problem-tramples-into-earnings-season-100005953.html?guccounter=2&guce_referrer=aHR0cHM6Ly9pbXRpYXpodW1heXVuLmdpdGh1Yi5pby8&guce_referrer_sig=AQAAAEhm3puu8JxRGsF28OsCvpk855Jy-md63h2BWRPSrG1KIp_-qmaywI2xfjZe5BH10JOcbFxxrApZeOU4XdRw5GPPtlCbkL2mPDGO2FvTXtEheMdNhvOxJVkU3ljKharc4oKQHWeQ6G1BxPibeWiMAiU6dwQnI8MONYqmBpon-7Zn">Yahoo!finance</a>,
		<a href="https://fortune.com/2024/04/18/linkedin-microsoft-collaborative-articles-generative-ai-feedback-loop-user-backlash/?456789">Fortune</a>,
		<a href="https://timesofindia.indiatimes.com/technology/times-techies/why-genai-can-become-a-threat-to-itself/articleshow/112725659.cms">Times of India</a>,
		<a href="https://www.sciencedaily.com/releases/2024/07/240730134759.htm?utm_source=chatgpt.com">Sciencedaily</a>,
		<a href="https://www.france24.com/en/live-news/20240805-inbred-gibberish-or-just-mad-warnings-rise-about-ai-models">France 24</a>, and
		<a href="https://montrealethics.ai/self-improving-diffusion-models-with-synthetic-data/">Montreal AI Ethics</a>,
			
		</p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
            <div class="two" id='alignerf_image'>
              <img src='images/walrus.png' width="160"></div>
            <img src='images/walrus.png' width="160">
          </div>
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2505.12161">
          <span class="papertitle">WaLRUS: Wavelets for Long-range Representation Using SSMs</span>
        </a>
        <br>
        <a href="https://scholar.google.com/citations?user=PuxS0ZkAAAAJ&hl=en">Hossein Babaie</a>,
        <a href="https://meljwhite.com/">Mel White</a>,
	<strong>Sina Alemohammad</strong>,
        <a href="https://richb.rice.edu/">Richard Baraniuk</a>
        <br>
        <em>arXiv</em>, 2025
        <br>
        /
        <a href="https://arxiv.org/abs/2505.12161">arXiv</a>
        <p></p>
        <p>
	We introduce a novel approach that integrates wavelet transforms with state-space models to effectively capture long‑range dependencies in sequences. 
      </td>
    </tr>

        <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
            <div class="two" id='alignerf_image'>
              <img src='images/safari.png' width="160"></div>
            <img src='images/safari.png' width="160">
          </div>
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2505.08977">
          <span class="papertitle">Safari: State-space models for frame-agnostic representation</span>
        </a>
        <br>
        <a href="https://scholar.google.com/citations?user=PuxS0ZkAAAAJ&hl=en">Hossein Babaie</a>,
        <a href="https://meljwhite.com/">Mel White</a>,
	<strong>Sina Alemohammad</strong>,
        <a href="https://richb.rice.edu/">Richard Baraniuk</a>
        <br>
        <em>arXiv</em>, 2025
        <br>
        /
        <a href="https://arxiv.org/abs/2505.08977">arXiv</a>
        <p></p>
        <p>
	We present SaFARi, a frame‑agnostic extension of state‑space models that generalizes HiPPO to support any functional basis, enabling flexible and efficient long-range sequence representation. 
      </td>
    </tr>

    <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
            <div class="two" id='alignerf_image'>
              <img src='images/sims.png' width="160"></div>
            <img src='images/sims.png' width="160">
          </div>
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2408.16333">
          <span class="papertitle">Self-improving diffusion models with synthetic data</span>
        </a>
        <br>
	<strong>Sina Alemohammad</strong>,
	<a href="https://imtiazhumayun.github.io/">Ahmed Imtiaz Humayun</a>,
	<a href="https://agarwalshruti15.github.io/">Shruti Agarwal</a>,
	<a href="https://www.surrey.ac.uk/people/john-collomosse">John Collomosse</a>,
        <a href="https://richb.rice.edu/">Richard Baraniuk</a>
        <br>
        <em>arXiv</em>, 2024
        <br>
        /
        <a href="https://arxiv.org/abs/2408.16333">arXiv</a>
        <p></p>
        <p>
	This work introduces SIMS, a novel training framework that uses a model’s own generated synthetic data as negative guidance to improve diffusion model performance while preventing model collapse—or “model autophagy disorder” (MAD). The method outperforms prior approaches by setting new Fréchet Inception Distance (FID) records on CIFAR‑10 and ImageNet‑64, and enables controlled bias adjustments in the synthetic data distribution
      </td>
    </tr>

   <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
            <div class="two" id='alignerf_image'>
              <img src='images/titan.png' width="160"></div>
            <img src='images/titan.png' width="160">
          </div>
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/10446136">
          <span class="papertitle">Titan: Bringing the Deep Image Prior to Implicit Representations</span>
        </a>
        <br>
        <a href="https://profiles.rice.edu/faculty/lorenzo-luzi">Lorenzo Luzi
	<a href="https://dlej.net/">Daniel Lejeune
	<a href="https://alisiahkoohi.github.io/">Ali Siahkoohi</a>,
	<strong>Sina Alemohammad</strong>,
	<a href="https://vishwa91.github.io/">Vishwanath Saragadam</a>,
	<a href="https://scholar.google.com/citations?user=PuxS0ZkAAAAJ&hl=en">Hossein Babaie</a>,
	<a href="https://scholar.google.com/citations?user=J0sOe2gAAAAJ&hl=en">Naiming Liu</a>,
	<a href="https://zichaow.github.io/">Zichao (Jack) Wang</a>,
        <a href="https://richb.rice.edu/">Richard Baraniuk</a>
        <br>
        <em>ICASSP</em>, 2024
        <br>
        /
        <a href="https://arxiv.org/abs/2211.00219">arXiv</a>
        <p></p>
        <p>
	We introduce TITAN, which enhances implicit neural representations by integrating deep image priors via a residual deep decoder, significantly improving interpolation quality in super-resolution and CT applications.
    </tr>

   <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
            <div class="two" id='alignerf_image'>
              <img src='images/ada.png' width="160"></div>
            <img src='images/ada.png' width="160">
          </div>
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://proceedings.mlr.press/v234/lejeune24a.html">
          <span class="papertitle">An Adaptive Tangent Feature Perspective of Neural Networks</span>
        </a>
        <br>
        
	<a href="https://dlej.net/">Daniel Lejeune
	
	<strong>Sina Alemohammad</strong>,
        <br>
        <em>CPAL</em>, 2024
        <br>
        /
        <a href="https://arxiv.org/abs/2308.15478">arXiv</a>
        <p></p>
        <p>
	We propose a framework that allows tangent features to adapt during training—equivalent to structured regularization—and demonstrate this adaptivity yields significantly lower sample complexity and better kernel alignment than fixed-feature models on MNIST and CIFAR‑10.
    </tr>

        <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
            <div class="two" id='alignerf_image'>
              <img src='images/mad.png' width="160"></div>
            <img src='images/mad.png' width="160">
          </div>
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://openreview.net/forum?id=ShjMHfmPs0">
          <span class="papertitle">Self-Consuming Generative Models Go MAD</span>
        </a>
        <br>
	<strong>Sina Alemohammad</strong>,
	<a href="https://sinaalemohammad.github.io/">Josue Casco-Rodriguez</a>,
	<a href="https://profiles.rice.edu/faculty/lorenzo-luzi">Lorenzo Luzi,
	<a href="https://imtiazhumayun.github.io/">Ahmed Imtiaz Humayun</a>,
	<a href="https://scholar.google.com/citations?user=PuxS0ZkAAAAJ&hl=en">Hossein Babaie</a>,
	<a href="https://dlej.net/">Daniel Lejeune
	<a href="https://alisiahkoohi.github.io/">Ali Siahkoohi</a>,
        <a href="https://richb.rice.edu/">Richard Baraniuk</a>
        <br>
        <em>ICLR</em>, 2024
        <br>
        /
        <a href="https://arxiv.org/abs/2307.01850">arXiv</a>
        <p></p>
        <p>
	We study the phenomenon of training new generative models with synthetic data from previous generative models. Our primary conclusion is that without enough fresh real data in each generation of a self-consuming or autophagous loop, future generative models are doomed to have their quality (precision) or diversity (recall) progressively decrease.
      </td>
    </tr>

    <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  >
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
            <div class="two" id='alignerf_image'>
              <img src='images/cov.png' width="160"></div>
            <img src='images/cov.png' width="160">
          </div>
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/10109666">
          <span class="papertitle">Covariate Balancing Methods for Randomized Controlled Trials Are Not Adversarially Robust</span>
        </a>
        <br>
	<a href="https://scholar.google.com/citations?user=PuxS0ZkAAAAJ&hl=en">Hossein Babaie</a>,
	<strong>Sina Alemohammad</strong>,
        <a href="https://richb.rice.edu/">Richard Baraniuk</a>
        <br>
        <em>IEEE Transactions on Neural Networks and Learning Systems</em>, Volume: 35, Issue: 4, 2024
        <br>
        /
        <a href="https://arxiv.org/pdf/2110.13262">arXiv</a>
        <p></p>
        <p>
	We show that commonly used covariate balancing techniques in randomized trials can be vulnerable to adversarial manipulation, undermining their reliability in worst-case scenarios.
      </td>
    </tr>

<tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  >
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
            <div class="two" id='alignerf_image'>
              <img src='images/neu.png' width="160"></div>
            <img src='images/neu.png' width="160">
          </div>
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://dl.acm.org/doi/abs/10.1145/3531146.3533224">
          <span class="papertitle">NeuroView-RNN: It’s About Time</span>
        </a>
        <br>
	<a href="https://scholar.google.com/citations?user=zNvD8nQAAAAJ&hl=en">CJ Barberan</a>,
	<strong>Sina Alemohammad</strong>,
	<a href="https://scholar.google.com/citations?user=J0sOe2gAAAAJ&hl=en">Naiming Liu</a>,
        <a href="https://richb.rice.edu/">Richard Baraniuk</a>
        <br>
        <em>FAccT</em>, 2022
        <br>
        /
        <a href="https://arxiv.org/abs/2202.11811">arXiv</a>
        <p></p>
        <p>
	We introduce a framework that enhances RNN interpretability by quantifying how each hidden state temporally contributes to model decisions, offering a clear, time-resolved understanding of sequence processing.
      </td>
    </tr>

        <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  >
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
            <div class="two" id='alignerf_image'>
              <img src='images/nftk.png' width="160"></div>
            <img src='images/nftk.png' width="160">
          </div>
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/9747078/authors#authors">
          <span class="papertitle">NFT-K: Non-Fungible Tangent Kernels</span>
        </a>
        <br>
	
	<strong>Sina Alemohammad</strong>,
	<a href="https://scholar.google.com/citations?user=PuxS0ZkAAAAJ&hl=en">Hossein Babaie</a>,
	<a href="https://scholar.google.com/citations?user=zNvD8nQAAAAJ&hl=en">CJ Barberan</a>,
	<a href="https://scholar.google.com/citations?user=J0sOe2gAAAAJ&hl=en">Naiming Liu</a>,
	<a href="https://profiles.rice.edu/faculty/lorenzo-luzi">Lorenzo Luzi,
	<a href="https://blakemas.github.io/">Blake Mason,
        <a href="https://richb.rice.edu/">Richard Baraniuk</a>
        <br>
        <em>ICASSP</em>, 2022
        <br>
        /
        <a href="https://arxiv.org/abs/2110.04945">arXiv</a>
        <p></p>
        <p>
	We propose NFT‑K, a novel neural architecture that models each layer of a deep network with its own individual tangent kernel—enhancing interpretability and performance over single-kernel approaches.
      </td>
    </tr>

    <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  >
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
            <div class="two" id='alignerf_image'>
              <img src='images/mask.png' width="160"></div>
            <img src='images/mask.png' width="160">
          </div>
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/9413450">
          <span class="papertitle">Wearing a mask: Compressed representations of variable-length sequences using recurrent neural tangent kernels</span>
        </a>
        <br>
	
	<strong>Sina Alemohammad</strong>,
	<a href="https://scholar.google.com/citations?user=PuxS0ZkAAAAJ&hl=en">Hossein Babaie</a>,
	<a href="https://randallbalestriero.github.io/">Randall Balestriero</a>,
	<a href="https://matthewyccheung.github.io/">Matt Y. Cheung</a>,
	<a href="https://imtiazhumayun.github.io/">Ahmed Imtiaz Humayun</a>,
	<a href="https://dlej.net/">Daniel Lejeune,
	<a href="https://scholar.google.com/citations?user=J0sOe2gAAAAJ&hl=en">Naiming Liu</a>,
	<a href="https://profiles.rice.edu/faculty/lorenzo-luzi">Lorenzo Luzi,
	<a href="https://tanjasper.github.io/">Jasper Tan,
	<a href="https://zichaow.github.io/">Zichao (Jack) Wang</a>,
        <a href="https://richb.rice.edu/">Richard Baraniuk</a>
        <br>
        <em>ICASSP</em>, 2021
        <br>
        /
        <a href="https://arxiv.org/abs/2010.13975">arXiv</a>
        <p></p>
        <p>
	We introduce a method for compressing variable-length sequences by combining recurrent neural tangent kernels with learned masks, enabling efficient and structured representations of long, complex data streams.
      </td>
    </tr>

        <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  >
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
            <div class="two" id='alignerf_image'>
              <img src='images/enhanced.png' width="160"></div>
            <img src='images/enhanced.png' width="160">
          </div>
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2012.04859">
          <span class="papertitle">Enhanced Recurrent Neural Tangent Kernels for Non-Time-Series Data</span>
        </a>
        <br>
	
	<strong>Sina Alemohammad</strong>,
	<a href="https://randallbalestriero.github.io/">Randall Balestriero</a>,
	<a href="https://zichaow.github.io/">Zichao (Jack) Wang</a>,
        <a href="https://richb.rice.edu/">Richard Baraniuk</a>
        <br>
        <em>arXiv</em>, 2021
        <br>
        /
        <a href="https://arxiv.org/abs/2012.04859">arXiv</a>
        <p></p>
        <p>
	We extend infinite-width recurrent neural tangent kernels to bidirectional and pooled RNN architectures, implement a fast GPU version, and demonstrate superior performance on 90 non‑time‑series UCI datasets.
      </td>
    </tr>

    <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
            <div class="two" id='alignerf_image'>
              <img src='images/RNTK.png' width="160"></div>
            <img src='images/RNTK.png' width="160">
          </div>
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://openreview.net/forum?id=3T9iFICe0Y9">
          <span class="papertitle">The Recurrent Neural Tangent Kernel </span>
        </a>
        <br>
	
	<strong>Sina Alemohammad</strong>,
	<a href="https://zichaow.github.io/">Zichao (Jack) Wang</a>,
	<a href="https://randallbalestriero.github.io/">Randall Balestriero</a>,
        <a href="https://richb.rice.edu/">Richard Baraniuk</a>
        <br>
        <em>ICLR</em>, 2021
        <br>
        /
        <a href="https://arxiv.org/abs/2006.10246">arXiv</a>
        <p></p>
        <p>
	We introduce the Recurrent Neural Tangent Kernel (RNTK), a kernel derived from the infinite-width limit of recurrent neural networks, which captures variable-length sequence inputs and provides improved performance on synthetic and real-world datasets.
      </td>
    </tr>

    </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                 The website template is borrowed from <a href="https://jonbarron.info/">Jon Barron</a>. 
                </p>
              </td>
            </tr>
</tbody></table>

		  
    </table>
  </body>
</html>
